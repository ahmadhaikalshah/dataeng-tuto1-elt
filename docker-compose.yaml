services:
  
  source_postgres:
    image: postgres:15
    ports:
      - "5433:5432"
    networks:
      - elt_network
    environment:
      POSTGRES_DB: source_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: secret
    volumes:
      - source_db_data:/var/lib/postgresql/data
      - ./source_db_init/init.sql/:/docker-entrypoint-initdb.d/init.sql

  destination_postgres:
    image: postgres:15
    ports:
      - "5434:5432"
    networks:
      - elt_network
    environment:
      POSTGRES_DB: destination_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: secret
    volumes:
      - destination_db_data:/var/lib/postgresql/data
  
  # elt_script:
  #   build:
  #     context: ./elt
  #     dockerfile: Dockerfile
  #   networks:
  #     - elt_network
  #   depends_on:
  #     - source_postgres
  #     - destination_postgres
  #   ports:
  #     - "${PORT_NO}:${PORT_NO}"
  #   environment:
  #     ELT_DIR: ${ELT_DIR}
  #     HOSTNAME: ${ELT_HOSTNAME}
  #     PORT_NO: ${PORT_NO}

  # dbt:
  #   image: ghcr.io/dbt-labs/dbt-postgres:1.9.latest
  #   entrypoint: /bin/sh
  #   command:
  #     - -c
  #     - |
  #       echo 'Installing bash and curl...';
  #       apt-get update;
  #       apt-get install bash;
  #       apt-get install -y curl;
  #       echo 'Waiting for ELT script to complete...';
  #       until curl --silent --fail http://${ELT_HOSTNAME}:${PORT_NO}; do
  #         echo 'Still waiting...';
  #         sleep 2;
  #       done;
  #       echo 'ELT done. Running DBT...';
  #       dbt run --profiles-dir /root --project-dir /dbt
  #   networks:
  #     - elt_network
  #   volumes:
  #     - ./custom_postgres:/dbt
  #     - ~/.dbt:/root
  #   depends_on:
  #     - ${ELT_HOSTNAME}
  #   environment:
  #     DBT_PROFILE: custom_postgres
  #     DBT_TARGET: dev
  
  airflow_postgres:
    image: postgres:15
    networks:
      elt_network
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
  
  airflow_init:
    image: apache/airflow:latest-python3.12
    depends_on:
      - airflow_postgres
    networks:
      - elt_network
    environment:
      - AIRFLOW__DATABASE_SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow_postgres/airflow
    command: >
      bash -c "airflow db init && airflow users create --username airflow --password password --firstname John --lastname Doe --role Admin --email admin@example.com"
  
  airflow_webserver:
    build:
      context: .
      dockerfile: Dockerfile
    user: root
    depends_on:
      - airflow_postgres
    networks:
      - elt_network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./elt:${ELT_AIRFLOW_DIR}
      - ./custom_postgres:/opt/dbt
      - ~/.dbt:/root/dbt
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - LOAD_EX=n
      - EXECUTOR=Local
      - AIRFLOW__DATABASE_SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow_postgres/airflow
      - AIRFLOW__CORE__FERNET_KEY=
      - AIRFLOW__WEBSERVER__DEFAULT__USER_USERNAME=airflow
      - AIRFLOW__WEBSERVER__DEFAULT__USER_PASSWORD=password
      - AIRFLOW_WWW_USER_USERNAME=airflow
      - AIRFLOW_WWW_USER_PASSWORD=password
      - AIRFLOW__WEBSERVER__SECRET_KEY=secret
      - ELT_DIR: ${ELT_AIRFLOW_DIR}
      - HOSTNAME: ${ELT_HOSTNAME}
      - PORT_NO: ${PORT_NO}
    ports:
      - "${PORT_NO}:${PORT_NO}"
    command: airflow_webserver
  
  airflow_scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    user: root
    depends_on:
      - airflow_postgres
    networks:
      - elt_network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./elt:${ELT_AIRFLOW_DIR}
      - ./custom_postgres:/opt/dbt
      - ~/.dbt:/root/dbt
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - LOAD_EX=n
      - EXECUTOR=Local
      - AIRFLOW__DATABASE_SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow_postgres/airflow
      - AIRFLOW__CORE__FERNET_KEY=
      - AIRFLOW__WEBSERVER__DEFAULT__USER_USERNAME=airflow
      - AIRFLOW__WEBSERVER__DEFAULT__USER_PASSWORD=password
      - AIRFLOW_WWW_USER_USERNAME=airflow
      - AIRFLOW_WWW_USER_PASSWORD=password
      - AIRFLOW__WEBSERVER__SECRET_KEY=secret
      - ELT_DIR: ${ELT_AIRFLOW_DIR}
      - HOSTNAME: ${ELT_HOSTNAME}
      - PORT_NO: ${PORT_NO}
    ports:
      - "${PORT_NO}:${PORT_NO}"
    command: airflow_scheduler

networks:
  elt_network:
    driver: bridge

volumes:
  source_db_data:
  destination_db_data: